{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0be70a-0b2f-4d12-ba6e-be6ca36f1c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import warnings\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pycountry\n",
    "import torch\n",
    "import wandb\n",
    "from datasets import load_dataset\n",
    "from sentence_transformers import util\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12db84d-4d97-4f7b-b700-6d4a81d6763c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb1ed6b-0cd8-405f-ab9d-9437b48e1e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e9f77d-305f-464d-8312-a524797ff6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed\n",
    "\n",
    "def embed(sentences: List[str]) -> np.ndarray:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a578b09-a52b-4843-82fd-fd461bee3ef4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6275ac9-6b9a-469f-aa29-4099c2c90382",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = wandb.config\n",
    "\n",
    "config.embedder = \"\"\n",
    "config.name = f\"tapaco-{config.embedder}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260902cf-74b7-45c2-9c11-7315ca0007ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1205518-6689-4331-995c-4ff09197e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(\n",
    "      entity=\"eenlp\",\n",
    "      project=\"paraphrase_detection\",\n",
    "      job_type=f\"create-dataset\",\n",
    "      name=f\"create-tapaco-{config.embedder}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08af5f44-4a6e-4ab3-bd14-a5e8700470db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET_ONLY_FIRST_N = 20_000\n",
    "DATASET_ONLY_FIRST_N = 10_000\n",
    "\n",
    "config.DATASET_ONLY_FIRST_N = DATASET_ONLY_FIRST_N\n",
    "\n",
    "dataset_name = \"tapaco\"\n",
    "\n",
    "dataset = load_dataset(\"tapaco\", \"all_languages\")\n",
    "df = dataset[\"train\"].to_pandas()\n",
    "\n",
    "df[\"paraphrase_set_id\"] = df[\"paraphrase_set_id\"].astype(int)\n",
    "\n",
    "languages_to_keep = [\n",
    "    \"be\",  # Belarusian\n",
    "    \"bg\",  # Bulgarian\n",
    "    \"cs\",  # Czech\n",
    "    \"en\",  # English\n",
    "    \"et\",  # Estonian\n",
    "    \"hr\",  # Croatian\n",
    "    \"hu\",  # Hungarian\n",
    "    \"hy\",  # Armenian\n",
    "    \"lt\",  # Lithuanian\n",
    "    \"mk\",  # Macedonian\n",
    "    \"pl\",  # Polish\n",
    "    \"ro\",  # Romanian\n",
    "    \"ru\",  # Russian\n",
    "    \"sl\",  # Slovenian\n",
    "    \"sr\",  # Serbian\n",
    "    \"uk\",  # Ukrainian\n",
    "]\n",
    "\n",
    "df = df[df[\"language\"].isin(languages_to_keep)]\n",
    "assert len(languages_to_keep) == len(\n",
    "    df[\"language\"].unique()\n",
    "), \"Count of filtered languages doesn't match, probably a typo in 'languages_to_keep'?\"\n",
    "\n",
    "# paraphrase_set_id = 0 seems to mean \"unassigned\".\n",
    "df = df[df[\"paraphrase_set_id\"] != 0].copy()\n",
    "\n",
    "# We need to generate example pairs somehow.\n",
    "# As of the current version of the code, 50% of the generated examples are true paraphrases (label = 1),\n",
    "# 25% are chosen from the most similar non-paraphrases (label = 0),\n",
    "# and 25% is random negative examples (label = 0).\n",
    "\n",
    "result = []\n",
    "np.random.seed(0)\n",
    "for language, df_language in tqdm(df.groupby(\"language\"), \"language\", position=0):\n",
    "    try:\n",
    "        language_name = pycountry.languages.get(alpha_2=language).name\n",
    "\n",
    "        df_language = df_language[:DATASET_ONLY_FIRST_N]\n",
    "\n",
    "        df_language[\"embeddings\"] = embed(df_language[\"paraphrase\"])\n",
    "\n",
    "        for paraphrase_set_id, df_set in tqdm(\n",
    "            df_language.groupby(\"paraphrase_set_id\"),\n",
    "            \"paraphrase_set_id\",\n",
    "            position=1,\n",
    "        ):\n",
    "            if len(df_set) <= 1:\n",
    "                continue\n",
    "\n",
    "            df_negatives = df_language[\n",
    "                df_language[\"paraphrase_set_id\"] != paraphrase_set_id\n",
    "            ]\n",
    "\n",
    "            for row in df_set.itertuples():\n",
    "                result.append(\n",
    "                    {\n",
    "                        \"sentence1\": row.paraphrase,\n",
    "                        \"sentence2\": np.random.choice(\n",
    "                            df_set[df_set.index != row.Index][\"paraphrase\"]\n",
    "                        ),\n",
    "                        \"label\": 1,\n",
    "                        \"lang\": language_name,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                # TODO this can sample the same pair twice, consider fixing it\n",
    "                result.append(\n",
    "                    {\n",
    "                        \"sentence1\": row.paraphrase,\n",
    "                        \"sentence2\": np.random.choice(\n",
    "                            df_set[df_set.index != row.Index][\"paraphrase\"]\n",
    "                        ),\n",
    "                        \"label\": 1,\n",
    "                        \"lang\": language_name,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                # similar negative\n",
    "                query_embedding = row.embedding\n",
    "                corpus_embeddings = df_negatives[\"embeddings\"]\n",
    "                cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\n",
    "                top_results = torch.topk(cos_scores, k=1)\n",
    "\n",
    "                result.append(\n",
    "                    {\n",
    "                        \"sentence1\": row.paraphrase,\n",
    "                        \"sentence2\": df_negatives.iloc[top_results[1][0]][\"paraphrase\"],\n",
    "                        \"label\": 0,\n",
    "                        \"lang\": language_name,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                # random negative\n",
    "                result.append(\n",
    "                    {\n",
    "                        \"sentence1\": row.paraphrase,\n",
    "                        \"sentence2\": np.random.choice(df_negatives[\"paraphrase\"]),\n",
    "                        \"label\": 0,\n",
    "                        \"lang\": language_name,\n",
    "                    }\n",
    "                )\n",
    "    except KeyboardInterrupt:\n",
    "        raise\n",
    "    except:\n",
    "        warnings.warn(traceback.format_exc())\n",
    "        continue\n",
    "\n",
    "result = pd.DataFrame(result)\n",
    "result[\"source\"] = dataset_name\n",
    "result[\"split\"] = \"train\"\n",
    "\n",
    "artifact = wandb.Artifact(name=config.name, type=\"tapaco-dataset\")\n",
    "artifact.add(wandb.Table(dataframe=result), \"data\")\n",
    "wandb.run.log_artifact(artifact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0122a3b6-8879-40ce-9e16-ae5e6db3b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.run.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eenlp_alternate",
   "language": "python",
   "name": "eenlp_alternate"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
