{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XjaVbSZDwJtN"
   },
   "outputs": [],
   "source": [
    "# set up the config\n",
    "class Config:\n",
    "    BATCH_SIZE = 16\n",
    "    MAX_LEN = 128\n",
    "    TARGET = 'label'\n",
    "    PROJECT = 'wsd'\n",
    "    MODEL = 'xlm-roberta-base'\n",
    "    LEARNING_RATE = 1e-05\n",
    "    EPOCHS = 10 # 5\n",
    "    EPS = 1e-08\n",
    "    random_seed = 0xfeedbeef\n",
    "    dataset = \"EENLP.WSD.WiC\"\n",
    "    full_data = \"wsd.wic.english.jsonl\"\n",
    "    eval_data = {\n",
    "        \"bulgarian\" :\"wsd.wic.bulgarian.jsonl\",\n",
    "        \"croatian\" :\"wsd.wic.croatian.jsonl\",\n",
    "        \"estonian\" :\"wsd.wic.estonian.jsonl\",\n",
    "        \"hungarian\"  :\"wsd.wic.hungarian.jsonl\",\n",
    "        \"russian\"  :\"wsd.wic.russian.jsonl\",\n",
    "        \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SX5LlemWwOFD",
    "outputId": "5eeba118-0630-48ac-b1be-990a3439ae1d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\"gdown\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n",
      "\"unzip\" ­Ґ пў«пҐвбп ў­гваҐ­­Ґ© Ё«Ё ў­Ґи­Ґ©\n",
      "Є®¬ ­¤®©, ЁбЇ®«­пҐ¬®© Їа®Ја ¬¬®© Ё«Ё Ї ЄҐв­л¬ д ©«®¬.\n"
     ]
    }
   ],
   "source": [
    "# get the data from Google Drive public link\n",
    "!gdown --id 1gk7evveMDbaXj7vw72ZuJnyu08bN5NZC\n",
    "!unzip `ls /content/*.zip`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we have GPU\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eCtG46ABwMks",
    "outputId": "a73e707c-17d2-4ed7-c105-26e41e1557cb"
   },
   "outputs": [],
   "source": [
    "# prepare env\n",
    "\n",
    "!pip install transformers\n",
    "!pip install wget\n",
    "!pip install urllib2\n",
    "!pip install wandb -qqq\n",
    "!pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "z7k_UZajwN0c"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import wandb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import TensorDataset, random_split\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification \n",
    "from transformers import get_linear_schedule_with_warmup, AdamW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bH9LlMiWwN8i",
    "outputId": "2f578952-3f6f-473d-8682-a6c62883a06e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: altsoph (use `wandb login --relogin` to force relogin)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">dark-dream-9</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/eenlp/wsd\" target=\"_blank\">https://wandb.ai/eenlp/wsd</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/eenlp/wsd/runs/2q0rnffj\" target=\"_blank\">https://wandb.ai/eenlp/wsd/runs/2q0rnffj</a><br/>\n",
       "                Run data is saved locally in <code>E:\\!Incoming_projects\\!EEML2021\\EENLP\\WSD\\res\\wandb\\run-20210725_234630-2q0rnffj</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Calling run.save without any arguments is deprecated.Changes to attributes are automatically persisted.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log in to your W&B account\n",
    "wandb.login()\n",
    "wandb.init(\n",
    "      entity=\"eenlp\",\n",
    "      project= Config.PROJECT, \n",
    "      # Track hyperparameters and run metadata\n",
    "      config=dict([(k,v) for k,v in Config.__dict__.items() if k[0]!='_']),\n",
    "      reinit=True\n",
    ")\n",
    "#     run = wandb.init(project=\"storydb_eval.task3\", reinit=True)\n",
    "wandb.run.name += f'_{Config.MODEL}'\n",
    "wandb.run.save()    \n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "id": "hVTOlxc8wN_i",
    "outputId": "d081e4bf-2a0a-4d27-a3dc-00fe65f9ee70"
   },
   "outputs": [],
   "source": [
    "label_encoder = None\n",
    "labels_codes = None\n",
    "\n",
    "def load_dataset(fn):\n",
    "    return pd.read_json(fn, lines=True) \n",
    "\n",
    "def load_dataset_and_split(fn, fraction=.8):\n",
    "    data = pd.read_json(fn, lines=True)\n",
    "    df_train=data.sample(frac=fraction,random_state=200)\n",
    "    df_test=data.drop(df_train.index).reset_index(drop=True)\n",
    "    df_train = df_train.reset_index(drop=True)\n",
    "    return df_train, df_test\n",
    "\n",
    "def process_dataset(data, tokenizer, seq=False):\n",
    "    global label_encoder, labels_codes\n",
    "    if label_encoder is None:\n",
    "        print('init of label encoder')\n",
    "        label_encoder = LabelEncoder().fit(data[Config.TARGET])\n",
    "        keys = list(sorted(set(data[Config.TARGET])))\n",
    "        labels = label_encoder.transform(keys)\n",
    "        labels_codes = dict(zip(keys, labels))\n",
    "    data[Config.TARGET] = label_encoder.transform(data[Config.TARGET])\n",
    "\n",
    "    input_ids = torch.tensor([])\n",
    "    attention_masks = torch.tensor([])\n",
    "\n",
    "    data['TEXT'] = data['sentence1'] + ' [SEP] ' + data['sentence1'] + ' [SEP] ' + data['word']\n",
    "    for sent in data.loc[:, 'TEXT']:\n",
    "        encoded_sent = tokenizer.encode_plus(sent, add_special_tokens = True,\n",
    "                                             max_length = Config.MAX_LEN, \n",
    "                                             padding = 'max_length',\n",
    "                                             pad_to_max_length=True,\n",
    "                                             truncation = True,\n",
    "                                             return_tensors = 'pt')\n",
    "        input_ids = torch.cat([input_ids, encoded_sent['input_ids']])\n",
    "        attention_masks = torch.cat([attention_masks, encoded_sent['attention_mask']])\n",
    "    labels = torch.tensor(data[Config.TARGET])\n",
    "    dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "    if seq:\n",
    "        return DataLoader(dataset, sampler = SequentialSampler(dataset), batch_size = Config.BATCH_SIZE)\n",
    "    else:\n",
    "        return DataLoader(dataset, sampler = RandomSampler(dataset), batch_size = Config.BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing and preparing data, it will take a while.\n",
      "english... \tinit of label encoder\n",
      "done.\n",
      "bulgarian... \tdone.\n",
      "croatian... \tdone.\n",
      "estonian... \tdone.\n",
      "hungarian... \tdone.\n",
      "russian... \tdone.\n"
     ]
    }
   ],
   "source": [
    "# fix PRNG\n",
    "random.seed(Config.random_seed)\n",
    "np.random.seed(Config.random_seed)\n",
    "torch.manual_seed(Config.random_seed)\n",
    "torch.cuda.manual_seed_all(Config.random_seed)\n",
    "\n",
    "# init tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(Config.MODEL, truncation=True, do_lower_case=False)\n",
    "\n",
    "# split english dataset\n",
    "print('parsing and preparing data, it will take a while.')\n",
    "print('english', end='... \\t')\n",
    "train_df, test_df = load_dataset_and_split(Config.full_data, .8)\n",
    "train_loader = process_dataset(train_df, tokenizer, seq=False)\n",
    "eval_loaders = dict()\n",
    "eval_loaders['english'] = process_dataset(test_df, tokenizer, seq=True)\n",
    "print('done.')\n",
    "# prepare eval for other languages\n",
    "for lang, filename in Config.eval_data.items():\n",
    "    print(lang, end='... \\t')\n",
    "    eval_loaders[lang] = process_dataset(load_dataset(filename), tokenizer, seq=True)\n",
    "    print('done.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XLMRobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(250002, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "   Config.MODEL,\n",
    "   num_labels = len(labels_codes),\n",
    "   output_attentions = False,\n",
    "   output_hidden_states = False    \n",
    ")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch, loader, scheduler=None):\n",
    "    model.train()\n",
    "\n",
    "    train_loss_accum = 0\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    \n",
    "    for index, (sentence, attention_mask, label) in tqdm(enumerate(loader)):\n",
    "        model.zero_grad()\n",
    "\n",
    "        sentence = sentence.to(device).long()\n",
    "        attention_mask = attention_mask.to(device).long()\n",
    "        label = label.to(device).long()\n",
    "\n",
    "        output = model(sentence, attention_mask = attention_mask, labels = label)\n",
    "        loss_value, logits = output[0], output[1]\n",
    "        train_loss_accum += loss_value.item()\n",
    "        fin_targets.extend(label.cpu().detach().numpy().tolist())\n",
    "        logits = logits.cpu().detach().numpy()\n",
    "        fin_outputs.extend(np.argmax(logits, axis=1))\n",
    "        \n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "        if scheduler:\n",
    "            scheduler.step()\n",
    "\n",
    "    avg_loss = train_loss_accum / index\n",
    "    train_accuracy = metrics.accuracy_score( fin_targets, fin_outputs )\n",
    "#     train_f1_micro = metrics.f1_score(fin_targets, fin_outputs, average='micro')\n",
    "#     train_f1_macro = metrics.f1_score(fin_targets, fin_outputs, average='macro')\n",
    "\n",
    "    wandb.log({\"train/loss\": avg_loss, \n",
    "               \"train/acc\":  train_accuracy,\n",
    "               \"train/f1\" : metrics.f1_score(fin_targets, fin_outputs),\n",
    "               \"train/prec\" : metrics.precision_score(fin_targets, fin_outputs),\n",
    "               \"train/rec\" : metrics.recall_score(fin_targets, fin_outputs),\n",
    "#                \"train/f1_macro\" : train_f1_macro,\n",
    "               \"epoch\":epoch,\n",
    "              })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model, testing_loader):\n",
    "    model.eval()\n",
    "    fin_targets=[]\n",
    "    fin_outputs=[]\n",
    "    with torch.no_grad():\n",
    "        for sentence, attention_mask, targets in testing_loader:\n",
    "            sentence = sentence.to(device).long()\n",
    "            attention_mask = attention_mask.to(device).long()\n",
    "            outputs = model(sentence, attention_mask = attention_mask)\n",
    "            fin_targets.extend(targets.cpu().detach().numpy().tolist())\n",
    "            logits = outputs.logits.cpu().detach().numpy()\n",
    "            fin_outputs.extend(np.argmax(logits, axis=1))\n",
    "#             break\n",
    "    return fin_targets, fin_outputs\n",
    "\n",
    "def eval_model(model, epoch=-1):\n",
    "    for lang, eval_loader in eval_loaders.items():\n",
    "        targets, preds = validation(model, eval_loader)\n",
    "        scores = dict()\n",
    "        scores[f'valid/acc/{lang}'] = metrics.accuracy_score( targets, preds )\n",
    "        scores[f'valid/f1/{lang}'] = metrics.f1_score(targets, preds) # , average='micro')\n",
    "#         scores[f'valid/f1_macro/{lang}'] = metrics.f1_score(targets, preds, average='macro')\n",
    "        scores[f'valid/prec/{lang}'] = metrics.precision_score(targets, preds)\n",
    "        scores[f'valid/rec/{lang}'] = metrics.recall_score(targets, preds)\n",
    "\n",
    "        scores['epoch'] = epoch\n",
    "        print(scores)\n",
    "        wandb.log(scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/english': 0.5012366034624897, 'valid/f1/english': 0.6677649643053266, 'valid/prec/english': 0.5012366034624897, 'valid/rec/english': 1.0, 'epoch': -1}\n",
      "{'valid/acc/bulgarian': 0.2249774571686204, 'valid/f1/bulgarian': 0.36731689363268316, 'valid/prec/bulgarian': 0.2249774571686204, 'valid/rec/bulgarian': 1.0, 'epoch': -1}\n",
      "{'valid/acc/croatian': 0.1015625, 'valid/f1/croatian': 0.18439716312056736, 'valid/prec/croatian': 0.1015625, 'valid/rec/croatian': 1.0, 'epoch': -1}\n",
      "{'valid/acc/estonian': 0.10040983606557377, 'valid/f1/estonian': 0.18249534450651766, 'valid/prec/estonian': 0.10040983606557377, 'valid/rec/estonian': 1.0, 'epoch': -1}\n",
      "{'valid/acc/hungarian': 0.49512987012987014, 'valid/f1/hungarian': 0.6623235613463627, 'valid/prec/hungarian': 0.49512987012987014, 'valid/rec/hungarian': 1.0, 'epoch': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/russian': 0.37, 'valid/f1/russian': 0.5401459854014599, 'valid/prec/russian': 0.37, 'valid/rec/russian': 1.0, 'epoch': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "304it [01:45,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/english': 0.5012366034624897, 'valid/f1/english': 0.6677649643053266, 'valid/prec/english': 0.5012366034624897, 'valid/rec/english': 1.0, 'epoch': 0}\n",
      "{'valid/acc/bulgarian': 0.2249774571686204, 'valid/f1/bulgarian': 0.36731689363268316, 'valid/prec/bulgarian': 0.2249774571686204, 'valid/rec/bulgarian': 1.0, 'epoch': 0}\n",
      "{'valid/acc/croatian': 0.1015625, 'valid/f1/croatian': 0.18439716312056736, 'valid/prec/croatian': 0.1015625, 'valid/rec/croatian': 1.0, 'epoch': 0}\n",
      "{'valid/acc/estonian': 0.10040983606557377, 'valid/f1/estonian': 0.18249534450651766, 'valid/prec/estonian': 0.10040983606557377, 'valid/rec/estonian': 1.0, 'epoch': 0}\n",
      "{'valid/acc/hungarian': 0.49512987012987014, 'valid/f1/hungarian': 0.6623235613463627, 'valid/prec/hungarian': 0.49512987012987014, 'valid/rec/hungarian': 1.0, 'epoch': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/russian': 0.37, 'valid/f1/russian': 0.5401459854014599, 'valid/prec/russian': 0.37, 'valid/rec/russian': 1.0, 'epoch': 0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "304it [01:45,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/english': 0.5663643858202803, 'valid/f1/english': 0.6636828644501279, 'valid/prec/english': 0.5428870292887029, 'valid/rec/english': 0.8536184210526315, 'epoch': 1}\n",
      "{'valid/acc/bulgarian': 0.2466185752930568, 'valid/f1/bulgarian': 0.370147003392386, 'valid/prec/bulgarian': 0.22794800371402044, 'valid/rec/bulgarian': 0.9839679358717435, 'epoch': 1}\n",
      "{'valid/acc/croatian': 0.125, 'valid/f1/croatian': 0.18545454545454543, 'valid/prec/croatian': 0.10240963855421686, 'valid/rec/croatian': 0.9807692307692307, 'epoch': 1}\n",
      "{'valid/acc/estonian': 0.20901639344262296, 'valid/f1/estonian': 0.18565400843881855, 'valid/prec/estonian': 0.10352941176470588, 'valid/rec/estonian': 0.8979591836734694, 'epoch': 1}\n",
      "{'valid/acc/hungarian': 0.4967532467532468, 'valid/f1/hungarian': 0.6630434782608696, 'valid/prec/hungarian': 0.4959349593495935, 'valid/rec/hungarian': 1.0, 'epoch': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/russian': 0.409, 'valid/f1/russian': 0.5400778210116732, 'valid/prec/russian': 0.37923497267759565, 'valid/rec/russian': 0.9378378378378378, 'epoch': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "304it [01:45,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/english': 0.6018136850783182, 'valid/f1/english': 0.6360211002260738, 'valid/prec/english': 0.5869262865090403, 'valid/rec/english': 0.694078947368421, 'epoch': 2}\n",
      "{'valid/acc/bulgarian': 0.2975653742110009, 'valid/f1/bulgarian': 0.36563517915309446, 'valid/prec/bulgarian': 0.22943280531425653, 'valid/rec/bulgarian': 0.8997995991983968, 'epoch': 2}\n",
      "{'valid/acc/croatian': 0.20703125, 'valid/f1/croatian': 0.19762845849802368, 'valid/prec/croatian': 0.11013215859030837, 'valid/rec/croatian': 0.9615384615384616, 'epoch': 2}\n",
      "{'valid/acc/estonian': 0.2766393442622951, 'valid/f1/estonian': 0.18097447795823662, 'valid/prec/estonian': 0.10209424083769633, 'valid/rec/estonian': 0.7959183673469388, 'epoch': 2}\n",
      "{'valid/acc/hungarian': 0.4902597402597403, 'valid/f1/hungarian': 0.6564551422319475, 'valid/prec/hungarian': 0.49261083743842365, 'valid/rec/hungarian': 0.9836065573770492, 'epoch': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/russian': 0.409, 'valid/f1/russian': 0.5245374094931617, 'valid/prec/russian': 0.3734249713631157, 'valid/rec/russian': 0.8810810810810811, 'epoch': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "304it [01:45,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/english': 0.629843363561418, 'valid/f1/english': 0.6139294926913156, 'valid/prec/english': 0.6432432432432432, 'valid/rec/english': 0.587171052631579, 'epoch': 3}\n",
      "{'valid/acc/bulgarian': 0.3904418394950406, 'valid/f1/bulgarian': 0.366447985004686, 'valid/prec/bulgarian': 0.23914373088685015, 'valid/rec/bulgarian': 0.7835671342685371, 'epoch': 3}\n",
      "{'valid/acc/croatian': 0.375, 'valid/f1/croatian': 0.2079207920792079, 'valid/prec/croatian': 0.11931818181818182, 'valid/rec/croatian': 0.8076923076923077, 'epoch': 3}\n",
      "{'valid/acc/estonian': 0.4979508196721312, 'valid/f1/estonian': 0.18604651162790697, 'valid/prec/estonian': 0.1111111111111111, 'valid/rec/estonian': 0.5714285714285714, 'epoch': 3}\n",
      "{'valid/acc/hungarian': 0.4772727272727273, 'valid/f1/hungarian': 0.6373873873873874, 'valid/prec/hungarian': 0.4854202401372213, 'valid/rec/hungarian': 0.9278688524590164, 'epoch': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/russian': 0.463, 'valid/f1/russian': 0.49859943977591037, 'valid/prec/russian': 0.38088445078459343, 'valid/rec/russian': 0.7216216216216216, 'epoch': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "304it [01:45,  2.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/english': 0.642209398186315, 'valid/f1/english': 0.6593406593406593, 'valid/prec/english': 0.6306306306306306, 'valid/rec/english': 0.6907894736842105, 'epoch': 4}\n",
      "{'valid/acc/bulgarian': 0.3255184851217313, 'valid/f1/bulgarian': 0.35904027420736934, 'valid/prec/bulgarian': 0.22833787465940056, 'valid/rec/bulgarian': 0.8396793587174348, 'epoch': 4}\n",
      "{'valid/acc/croatian': 0.2578125, 'valid/f1/croatian': 0.20168067226890757, 'valid/prec/croatian': 0.11320754716981132, 'valid/rec/croatian': 0.9230769230769231, 'epoch': 4}\n",
      "{'valid/acc/estonian': 0.26229508196721313, 'valid/f1/estonian': 0.17050691244239632, 'valid/prec/estonian': 0.09610389610389611, 'valid/rec/estonian': 0.7551020408163265, 'epoch': 4}\n",
      "{'valid/acc/hungarian': 0.48214285714285715, 'valid/f1/hungarian': 0.6490649064906491, 'valid/prec/hungarian': 0.48841059602649006, 'valid/rec/hungarian': 0.9672131147540983, 'epoch': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/russian': 0.434, 'valid/f1/russian': 0.5162393162393162, 'valid/prec/russian': 0.3775, 'valid/rec/russian': 0.8162162162162162, 'epoch': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "304it [01:45,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/english': 0.640560593569662, 'valid/f1/english': 0.6506410256410257, 'valid/prec/english': 0.634375, 'valid/rec/english': 0.6677631578947368, 'epoch': 5}\n",
      "{'valid/acc/bulgarian': 0.3611361587015329, 'valid/f1/bulgarian': 0.36314606741573036, 'valid/prec/bulgarian': 0.23406720741599074, 'valid/rec/bulgarian': 0.8096192384769539, 'epoch': 5}\n",
      "{'valid/acc/croatian': 0.37890625, 'valid/f1/croatian': 0.22815533980582525, 'valid/prec/croatian': 0.13055555555555556, 'valid/rec/croatian': 0.9038461538461539, 'epoch': 5}\n",
      "{'valid/acc/estonian': 0.36885245901639346, 'valid/f1/estonian': 0.18085106382978722, 'valid/prec/estonian': 0.10397553516819572, 'valid/rec/estonian': 0.6938775510204082, 'epoch': 5}\n",
      "{'valid/acc/hungarian': 0.4837662337662338, 'valid/f1/hungarian': 0.6434977578475336, 'valid/prec/hungarian': 0.4889267461669506, 'valid/rec/hungarian': 0.940983606557377, 'epoch': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/russian': 0.457, 'valid/f1/russian': 0.49953917050691243, 'valid/prec/russian': 0.37902097902097903, 'valid/rec/russian': 0.7324324324324324, 'epoch': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "304it [01:46,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/english': 0.6248969497114591, 'valid/f1/english': 0.6497305619707467, 'valid/prec/english': 0.6107091172214182, 'valid/rec/english': 0.694078947368421, 'epoch': 6}\n",
      "{'valid/acc/bulgarian': 0.36339044183949504, 'valid/f1/bulgarian': 0.3622402890695573, 'valid/prec/bulgarian': 0.23381924198250728, 'valid/rec/bulgarian': 0.8036072144288577, 'epoch': 6}\n",
      "{'valid/acc/croatian': 0.3359375, 'valid/f1/croatian': 0.20930232558139533, 'valid/prec/croatian': 0.11904761904761904, 'valid/rec/croatian': 0.8653846153846154, 'epoch': 6}\n",
      "{'valid/acc/estonian': 0.3524590163934426, 'valid/f1/estonian': 0.1979695431472081, 'valid/prec/estonian': 0.11304347826086956, 'valid/rec/estonian': 0.7959183673469388, 'epoch': 6}\n",
      "{'valid/acc/hungarian': 0.487012987012987, 'valid/f1/hungarian': 0.6473214285714285, 'valid/prec/hungarian': 0.4906937394247039, 'valid/rec/hungarian': 0.9508196721311475, 'epoch': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/russian': 0.444, 'valid/f1/russian': 0.49454545454545457, 'valid/prec/russian': 0.3726027397260274, 'valid/rec/russian': 0.7351351351351352, 'epoch': 6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "304it [01:45,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/english': 0.6240725474031328, 'valid/f1/english': 0.6369426751592356, 'valid/prec/english': 0.6172839506172839, 'valid/rec/english': 0.6578947368421053, 'epoch': 7}\n",
      "{'valid/acc/bulgarian': 0.3746618575293057, 'valid/f1/bulgarian': 0.3587609801202034, 'valid/prec/bulgarian': 0.23317307692307693, 'valid/rec/bulgarian': 0.7775551102204409, 'epoch': 7}\n",
      "{'valid/acc/croatian': 0.404296875, 'valid/f1/croatian': 0.19098143236074272, 'valid/prec/croatian': 0.11076923076923077, 'valid/rec/croatian': 0.6923076923076923, 'epoch': 7}\n",
      "{'valid/acc/estonian': 0.45081967213114754, 'valid/f1/estonian': 0.16770186335403728, 'valid/prec/estonian': 0.0989010989010989, 'valid/rec/estonian': 0.5510204081632653, 'epoch': 7}\n",
      "{'valid/acc/hungarian': 0.46915584415584416, 'valid/f1/hungarian': 0.6254295532646048, 'valid/prec/hungarian': 0.48063380281690143, 'valid/rec/hungarian': 0.8950819672131147, 'epoch': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/russian': 0.467, 'valid/f1/russian': 0.48000000000000004, 'valid/prec/russian': 0.3755725190839695, 'valid/rec/russian': 0.6648648648648648, 'epoch': 7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "304it [01:45,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/english': 0.6224237427864798, 'valid/f1/english': 0.6388012618296529, 'valid/prec/english': 0.6136363636363636, 'valid/rec/english': 0.6661184210526315, 'epoch': 8}\n",
      "{'valid/acc/bulgarian': 0.37060414788097384, 'valid/f1/bulgarian': 0.3608058608058608, 'valid/prec/bulgarian': 0.2338278931750742, 'valid/rec/bulgarian': 0.7895791583166333, 'epoch': 8}\n",
      "{'valid/acc/croatian': 0.388671875, 'valid/f1/croatian': 0.19948849104859334, 'valid/prec/croatian': 0.11504424778761062, 'valid/rec/croatian': 0.75, 'epoch': 8}\n",
      "{'valid/acc/estonian': 0.4016393442622951, 'valid/f1/estonian': 0.16571428571428573, 'valid/prec/estonian': 0.09634551495016612, 'valid/rec/estonian': 0.5918367346938775, 'epoch': 8}\n",
      "{'valid/acc/hungarian': 0.474025974025974, 'valid/f1/hungarian': 0.6292906178489702, 'valid/prec/hungarian': 0.4833040421792619, 'valid/rec/hungarian': 0.9016393442622951, 'epoch': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/russian': 0.463, 'valid/f1/russian': 0.48414985590778103, 'valid/prec/russian': 0.37555886736214605, 'valid/rec/russian': 0.6810810810810811, 'epoch': 8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "304it [01:45,  2.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid/acc/english': 0.6265457543281121, 'valid/f1/english': 0.6384676775738228, 'valid/prec/english': 0.6201550387596899, 'valid/rec/english': 0.6578947368421053, 'epoch': 9}\n",
      "{'valid/acc/bulgarian': 0.3769161406672678, 'valid/f1/bulgarian': 0.35840297121634174, 'valid/prec/bulgarian': 0.23323262839879155, 'valid/rec/bulgarian': 0.7735470941883767, 'epoch': 9}\n",
      "{'valid/acc/croatian': 0.390625, 'valid/f1/croatian': 0.1958762886597938, 'valid/prec/croatian': 0.1130952380952381, 'valid/rec/croatian': 0.7307692307692307, 'epoch': 9}\n",
      "{'valid/acc/estonian': 0.4385245901639344, 'valid/f1/estonian': 0.15950920245398775, 'valid/prec/estonian': 0.09386281588447654, 'valid/rec/estonian': 0.5306122448979592, 'epoch': 9}\n",
      "{'valid/acc/hungarian': 0.46915584415584416, 'valid/f1/hungarian': 0.6245694603903559, 'valid/prec/hungarian': 0.48056537102473496, 'valid/rec/hungarian': 0.8918032786885246, 'epoch': 9}\n",
      "{'valid/acc/russian': 0.47, 'valid/f1/russian': 0.47937131630648333, 'valid/prec/russian': 0.3765432098765432, 'valid/rec/russian': 0.6594594594594595, 'epoch': 9}\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr = Config.LEARNING_RATE, eps = Config.EPS)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, \n",
    "                                            num_training_steps = Config.EPOCHS*len(train_df)/Config.BATCH_SIZE)\n",
    "\n",
    "eval_model(model, epoch=-1)\n",
    "for epoch in range(Config.EPOCHS):\n",
    "    train(model, epoch, train_loader, scheduler)\n",
    "    eval_model(model, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "qolqX_cS1wjW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
